Technology Deep Dive Track  
Moving from Lambda and Kappa Architectures to Kappa+ at Uber
 
Kappa+ is a new approach developed at Uber to overcome the limitations of the Lambda and Kappa architectures. Whether your realtime infrastructure processes data at Uber scale (well over a trillion messages daily) or only a fraction of that, chances are you will need to reprocess old data at some point.

There can be many reasons for this. Perhaps a bug fix in the realtime code needs to be retroactively applied (aka backfill), or there is a need to train realtime machine learning models on last few months of data before bringing the models online. Kafka's data retention is limited in practice and generally insufficient for such needs. So data must be processed from archives. Aside from addressing such situations, enabling efficient stream processing on archived as well as realtime data also broadens the applicability of stream processing.

This talk introduces the Kappa+ architecture which enables the reuse of streaming realtime logic (stateful and stateless) to efficiently process any amounts of historic data without requiring it to be in Kafka. We shall discuss the complexities involved in such kind of processing and the specific techniques employed in Kappa+ to tackle them.

Kappa+是Uber为克服lambda和Kappa体系结构的局限性而开发的一种新方法。无论您的实时基础设施是以Uber的规模处理数据（每天超过一万亿条消息），还是仅处理其中的一小部分，您都有可能需要在某个时刻重新处理旧数据。

这有很多原因。也许实时代码中的错误修复需要追溯应用（又称回补），或者在将模型联机之前，需要根据过去几个月的数据培训实时机器学习模型。卡夫卡的数据保留在实践中是有限的，一般不足以满足这些需求。因此，必须从档案中处理数据。除了解决这类情况外，对存档数据和实时数据进行高效的流处理也扩大了流处理的适用性。

本文介绍了Kappa+体系结构，该体系结构使流实时逻辑（有状态和无状态）的重用能够有效地处理任何数量的历史数据，而无需将其放在kafka中。我们将讨论这类加工过程中涉及的复杂性，以及Kappa+所采用的解决这些问题的具体技术。

Authors
Roshan Naik
Roshan Naik
Uber